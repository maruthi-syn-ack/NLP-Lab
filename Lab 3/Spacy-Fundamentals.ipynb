{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21487178-0932-41f8-aa23-9f6fee0f8a37",
   "metadata": {},
   "source": [
    "Senetence and Word Tokenization using Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1358516-beda-4784-ba99-a9e2ae3c461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (23.3.1)\n",
      "Requirement already satisfied: setuptools in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (68.2.2)\n",
      "Requirement already satisfied: wheel in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (0.41.2)\n",
      "Requirement already satisfied: spacy in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy) (1.26.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting en-core-web-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from en-core-web-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dell/Documents/NLP/1SI20AD009/NLP/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Instalation \n",
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab15916-3ed2-4ec4-accf-86f78677d108",
   "metadata": {},
   "source": [
    "# Perform Sentence and Word tokenaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b81bdce5-70e4-4f01-8301-925d758af486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word tokens:\n",
      "1 SpaCy\n",
      "2 is\n",
      "3 an\n",
      "4 awesome\n",
      "5 library\n",
      "6 for\n",
      "7 natural\n",
      "8 language\n",
      "9 processing\n",
      "10 .\n",
      "11 It\n",
      "12 's\n",
      "13 easy\n",
      "14 to\n",
      "15 use\n",
      "16 and\n",
      "17 provides\n",
      "18 excellent\n",
      "19 features\n",
      "20 .\n",
      "\n",
      "Sentence tokens:\n",
      "1 SpaCy is an awesome library for natural language processing.\n",
      "2 It's easy to use and provides excellent features.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries \n",
    "import spacy\n",
    "\n",
    "# Load the language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Text to tokenize\n",
    "text = \"SpaCy is an awesome library for natural language processing. It's easy to use and provides excellent features.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "doc = nlp(text)\n",
    "\n",
    "# Word tokenization\n",
    "print(\"Word tokens:\")\n",
    "dcount =0\n",
    "for (token) in (doc):\n",
    "    # print(dcount+1)\n",
    "    dcount=dcount+1\n",
    "    print(dcount,token.text)\n",
    "\n",
    "# Sentence tokenization\n",
    "print(\"\\nSentence tokens:\")\n",
    "scount =0\n",
    "for sentence in doc.sents:\n",
    "    # print(sentence.text)\n",
    "    scount=scount+1\n",
    "    print(scount,sentence.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfeda88-f056-4c4b-9e11-1f44eb80b7ee",
   "metadata": {},
   "source": [
    "# Remove punctuation in text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a4f6f-9c1a-43ae-8ecd-e7b9a34480c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Process the text using SpaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Filter out tokens that are not punctuation\n",
    "    tokens_without_punct = [token.text for token in doc if not token.is_punct]\n",
    "\n",
    "    # Join the filtered tokens back into a string\n",
    "    return ' '.join(tokens_without_punct)\n",
    "\n",
    "# Example text\n",
    "text_with_punctuation = \"Hello, this is an example sentence! It has punctuation.\"\n",
    "\n",
    "# Remove punctuation\n",
    "text_without_punctuation = remove_punctuation(text_with_punctuation)\n",
    "print(text_without_punctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df6a6b2-5fef-49c5-b042-662cbdacb2e4",
   "metadata": {},
   "source": [
    "# Remove Stops words in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a8253-572a-4858-8562-612ce4328243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctualsion\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40850faa-690e-46af-9e6a-93dfe7bd2d19",
   "metadata": {},
   "source": [
    "# Tag the words in a given text using POS tagger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0998c5fe-d449-4e54-ae71-6748be4ac4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learn', 'php', 'from', 'guru99']\n",
      "[('learn', 'JJ'), ('php', 'NN'), ('from', 'IN'), ('guru99', 'NN')]\n",
      "(S (NP learn/JJ php/NN) from/IN (NP guru99/NN))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text = \"learn php from guru99\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)\n",
    "tag = nltk.pos_tag(tokens)\n",
    "print(tag)\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "cp  =nltk.RegexpParser(grammar)\n",
    "result = cp.parse(tag)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a93193-e6d7-4915-83b9-11c47dd445f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My PRON\n",
      "name NOUN\n",
      "is AUX\n",
      "Shaurya PROPN\n",
      "Uppal PROPN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "I PRON\n",
      "enjoy VERB\n",
      "writing VERB\n",
      "articles NOUN\n",
      "on ADP\n",
      "GeeksforGeeks PROPN\n",
      "checkout VERB\n",
      "\n",
      " SPACE\n",
      "my PRON\n",
      "other ADJ\n",
      "article NOUN\n",
      "by ADP\n",
      "going VERB\n",
      "to ADP\n",
      "my PRON\n",
      "profile NOUN\n",
      "section NOUN\n",
      ". PUNCT\n",
      "Verbs: ['enjoy', 'writing', 'checkout', 'going']\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "# Load English tokenizer, tagger, \n",
    "# parser, NER and word vectors \n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Process whole documents \n",
    "text = (\"\"\"My name is Shaurya Uppal. \n",
    "I enjoy writing articles on GeeksforGeeks checkout \n",
    "my other article by going to my profile section.\"\"\") \n",
    "\n",
    "doc = nlp(text) \n",
    "\n",
    "# Token and Tag \n",
    "for token in doc: \n",
    "    print(token, token.pos_) \n",
    "\n",
    "# You want list of Verb tokens \n",
    "print(\"Verbs:\", [token.text for token in doc if token.pos_ == \"VERB\"]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c079b-c6f6-46a0-8de5-d62d7d503986",
   "metadata": {},
   "source": [
    "# Steming and lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd0fc86-572b-490f-926a-931523baa1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'determined', 'drop', 'litigation', 'monastry', ',', 'relinguish', 'claims', 'wood-cuting', 'fishery', 'rihgts', '.', 'He', 'ready', 'becuase', 'rights', 'become', 'much', 'less', 'valuable', ',', 'indeed', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n",
      "['he', 'determin', 'drop', 'litig', 'monastri', ',', 'relinguish', 'claim', 'wood-cut', 'fisheri', 'rihgt', '.', 'he', 'readi', 'becuas', 'right', 'becom', 'much', 'less', 'valuabl', ',', 'inde', 'vaguest', 'idea', 'wood', 'river', 'question', '.']\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "set(stopwords.words('english'))\n",
    "\n",
    "text = \"\"\"He determined to drop his litigation with the monastry, and relinguish his claims to the wood-cuting and \n",
    "fishery rihgts at once. He was the more ready to do this becuase the rights had become much less valuable, and he had \n",
    "indeed the vaguest idea where the wood and river in question were.\"\"\"\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "word_tokens = word_tokenize(text) \n",
    "    \n",
    "filtered_sentence = [] \n",
    "  \n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "\n",
    "Stem_words = []\n",
    "ps =PorterStemmer()\n",
    "for w in filtered_sentence:\n",
    "    rootWord=ps.stem(w)\n",
    "    Stem_words.append(rootWord)\n",
    "print(filtered_sentence)\n",
    "print(Stem_words)\n",
    "\n",
    "\n",
    "\n",
    "#steamming in spacy is not possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08314c02-1df3-4843-b506-34585135b01a",
   "metadata": {},
   "source": [
    "# User defined Function for Coustom stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0accc364-077d-4b46-a55d-eab50bbf0364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'text', 'with', 'some', 'custom', 'stop', 'words', 'you', 'want', 'to', 'remove.', 'IIT', 'is', 'far', 'better', 'than', 'MIT']\n",
      "['This', 'is', 'a', 'sample', 'text', 'with', 'some', 'custom', 'stop', 'words', 'you', 'want', 'remove.', 'is', 'far', 'better', 'than', 'MIT']\n",
      "This is a sample text with some custom stop words you want remove. is far better than MIT\n"
     ]
    }
   ],
   "source": [
    "def remove_coustom_stopwords(text, custom_stopwords):\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "    print(words)\n",
    "    \n",
    "    # Filter out the custom stop words\n",
    "    filtered_words = [word for word in words if word.lower() not in custom_stopwords]\n",
    "    print(filtered_words)\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_text\n",
    "\n",
    "# Define your custom list of stop words\n",
    "custom_stopwords = [\"iit\",\"the\",\"to\"]\n",
    "\n",
    "# Example usage\n",
    "text = \"This is a sample text with some custom stop words you want to remove. IIT is far better than MIT\"\n",
    "filtered_text = remove_coustom_stopwords(text, custom_stopwords)\n",
    "print(filtered_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
