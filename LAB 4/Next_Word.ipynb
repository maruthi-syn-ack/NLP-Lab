{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b1d999-35a0-4fdc-a8e9-67e558a292ce",
   "metadata": {},
   "source": [
    "# Program to Predict next  word using N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30fd4b3c-6ad0-416b-a2b3-33663a1c975b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering...\n",
      "Cleaning...\n",
      "Making model...\n",
      "Enter a phrase: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I would\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['talk']\n",
      "i would talk\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['on']\n",
      "i would talk on\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['such']\n",
      "i would talk on such\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['a']\n",
      "i would talk on such a\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['thing', 'nice', 'capital', 'curious', 'fall', 'that', 'very', 'dear', 'subject', 'trial', 'tiny', 'sure', 'wretched', 'neck', 'new', 'noise', 'long', 'mousetrap', 'rule', 'puzzled', 'pleasant', 'simple', 'dreadful', 'hurry']\n",
      "i would talk on such a capital\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['one']\n",
      "i would talk on such a capital one\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['for']\n",
      "i would talk on such a capital one for\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['catching']\n",
      "i would talk on such a capital one for catching\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['miceoh', 'mouse']\n",
      "i would talk on such a capital one for catching miceoh\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['i']\n",
      "i would talk on such a capital one for catching miceoh i\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['beg']\n",
      "i would talk on such a capital one for catching miceoh i beg\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['your', 'pardon']\n",
      "i would talk on such a capital one for catching miceoh i beg your\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['pardon', 'acceptance']\n",
      "i would talk on such a capital one for catching miceoh i beg your pardon\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model predictions:  ['cried', 'said', 'she']\n",
      "i would talk on such a capital one for catching miceoh i beg your pardon cried\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to generate another word? (type 'y' for yes or 'n' for no):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "import random\n",
    "import nltk\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "\n",
    "\n",
    "def main():\n",
    "    file = open('alice.txt', 'r')\n",
    "    text = \"\"\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        text += line\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "    # pre-process text\n",
    "    print(\"Filtering...\")\n",
    "    words = filter(text)\n",
    "    print(\"Cleaning...\")\n",
    "    words = clean(words)\n",
    "\n",
    "    # make language model\n",
    "    print(\"Making model...\")\n",
    "    model = n_gram_model(words)\n",
    "\n",
    "    print(\"Enter a phrase: \")\n",
    "    user_input = input()\n",
    "    predict(model, user_input)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Normalize text, remove unnecessary characters, \n",
    "    perform regex parsing, and make lowercase\n",
    "\"\"\"\n",
    "def filter(text):\n",
    "    # normalize text\n",
    "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore'))\n",
    "    # replace html chars with ' '\n",
    "    text = re.sub('<.*?>', ' ', text)\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans(' ', ' ', string.punctuation))\n",
    "    # only alphabets and numerics\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # replace newline with space\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    # lower case\n",
    "    text = text.lower()\n",
    "    # split and join the words\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "\"\"\"\n",
    "    Tokenize remaining words\n",
    "    and perform lemmatization\n",
    "\"\"\"\n",
    "def clean(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    output = []\n",
    "    for words in tokens:\n",
    "        # lemmatize words\n",
    "        output.append(wnl.lemmatize(words))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Make a language model using a dictionary, trigrams, \n",
    "    and calculate word probabilities\n",
    "\"\"\"\n",
    "def n_gram_model(text):\n",
    "    trigrams = list(nltk.ngrams(text, 3, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
    "    # bigrams = list(nltk.ngrams(text, 2, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
    "\n",
    "# N-gram Statistics\n",
    "    # get freq dist of trigrams\n",
    "    # freq_tri = nltk.FreqDist(trigrams)\n",
    "    # freq_bi = nltk.FreqDist(bigrams)\n",
    "    # freq_tri.plot(30, cumulative=False)\n",
    "    # print(\"Most common trigrams: \", freq_tri.most_common(5))\n",
    "    # print(\"Most common bigrams: \", freq_bi.most_common(5))\n",
    "\n",
    "    # make conditional frequencies dictionary\n",
    "    cfdist = ConditionalFreqDist()\n",
    "    for w1, w2, w3 in trigrams:\n",
    "        cfdist[(w1, w2)][w3] += 1\n",
    "\n",
    "    # transform frequencies to probabilities\n",
    "    for w1_w2 in cfdist:\n",
    "        total_count = float(sum(cfdist[w1_w2].values()))\n",
    "        for w3 in cfdist[w1_w2]:\n",
    "            cfdist[w1_w2][w3] /= total_count\n",
    "\n",
    "    return cfdist\n",
    "\n",
    "\"\"\"\n",
    "    Generate predictions from the Conditional Frequency Distribution\n",
    "    dictionary (param: model), append weighted random choice to user's phrase,\n",
    "    allow option to generate more words following the prediction\n",
    "\"\"\"\n",
    "def predict(model, user_input):\n",
    "    user_input = filter(user_input)\n",
    "    user_input = user_input.split()\n",
    "\n",
    "    w1 = len(user_input) - 2\n",
    "    w2 = len(user_input)\n",
    "    prev_words = user_input[w1:w2]\n",
    "\n",
    "    # display prediction from highest to lowest maximum likelihood\n",
    "    prediction = sorted(dict(model[prev_words[0], prev_words[1]]), key=lambda x: dict(model[prev_words[0], prev_words[1]])[x], reverse=True)\n",
    "    print(\"Trigram model predictions: \", prediction)\n",
    "\n",
    "    word = []\n",
    "    weight = []\n",
    "    for key, prob in dict(model[prev_words[0], prev_words[1]]).items():\n",
    "        word.append(key)\n",
    "        weight.append(prob)\n",
    "    # pick from a weighted random probability of predictions\n",
    "    next_word = random.choices(word, weights=weight, k=1)\n",
    "    # add predicted word to user input\n",
    "    user_input.append(next_word[0])\n",
    "    print(' '.join(user_input))\n",
    "\n",
    "    ask = input(\"Do you want to generate another word? (type 'y' for yes or 'n' for no): \")\n",
    "    if ask.lower() == 'y':\n",
    "        predict(model, str(user_input))\n",
    "    elif ask.lower() == 'n':\n",
    "        print(\"done\")\n",
    "        \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "523f710e-2406-4c76-ab00-a5330fa2eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import random\n",
    "import nltk\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "def main():\n",
    "    # Load the \"gutenberg\" corpus\n",
    "    corpus_text = \" \".join(gutenberg.raw(file_id) for file_id in gutenberg.fileids())\n",
    "    # Pre-process text\n",
    "    print(\"Filtering...\")\n",
    "    words = filter(corpus_text)\n",
    "    print(\"Cleaning...\")\n",
    "    words = clean(words)\n",
    "\n",
    "    # Make language model\n",
    "    print(\"Making model...\")\n",
    "    model = n_gram_model(words)\n",
    "\n",
    "    print(\"Enter a phrase: \")\n",
    "    user_input = input()\n",
    "    predict(model, user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023e7dab-b275-4562-8a42-b6bc5dd929f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Normalize text, remove unnecessary characters, \n",
    "    perform regex parsing, and make lowercase\n",
    "\"\"\"\n",
    "def filter(text):\n",
    "    # normalize text\n",
    "    text = (unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore'))\n",
    "    # replace html chars with ' '\n",
    "    text = re.sub('<.*?>', ' ', text)\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans(' ', ' ', string.punctuation))\n",
    "    # only alphabets and numerics\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # replace newline with space\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    # lower case\n",
    "    text = text.lower()\n",
    "    # split and join the words\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "\"\"\"\n",
    "    Tokenize remaining words\n",
    "    and perform lemmatization\n",
    "\"\"\"\n",
    "def clean(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    output = []\n",
    "    for words in tokens:\n",
    "        # lemmatize words\n",
    "        output.append(wnl.lemmatize(words))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Make a language model using a dictionary, trigrams, \n",
    "    and calculate word probabilities\n",
    "\"\"\"\n",
    "def n_gram_model(text):\n",
    "    trigrams = list(nltk.ngrams(text, 3, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
    "    # bigrams = list(nltk.ngrams(text, 2, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
    "\n",
    "# N-gram Statistics\n",
    "    # get freq dist of trigrams\n",
    "    # freq_tri = nltk.FreqDist(trigrams)\n",
    "    # freq_bi = nltk.FreqDist(bigrams)\n",
    "    # freq_tri.plot(30, cumulative=False)\n",
    "    # print(\"Most common trigrams: \", freq_tri.most_common(5))\n",
    "    # print(\"Most common bigrams: \", freq_bi.most_common(5))\n",
    "\n",
    "    # make conditional frequencies dictionary\n",
    "    cfdist = ConditionalFreqDist()\n",
    "    for w1, w2, w3 in trigrams:\n",
    "        cfdist[(w1, w2)][w3] += 1\n",
    "\n",
    "    # transform frequencies to probabilities\n",
    "    for w1_w2 in cfdist:\n",
    "        total_count = float(sum(cfdist[w1_w2].values()))\n",
    "        for w3 in cfdist[w1_w2]:\n",
    "            cfdist[w1_w2][w3] /= total_count\n",
    "\n",
    "    return cfdist\n",
    "\n",
    "\"\"\"\n",
    "    Generate predictions from the Conditional Frequency Distribution\n",
    "    dictionary (param: model), append weighted random choice to user's phrase,\n",
    "    allow option to generate more words following the prediction\n",
    "\"\"\"\n",
    "def predict(model, user_input):\n",
    "    user_input = filter(user_input)\n",
    "    user_input = user_input.split()\n",
    "\n",
    "    w1 = len(user_input) - 2\n",
    "    w2 = len(user_input)\n",
    "    prev_words = user_input[w1:w2]\n",
    "\n",
    "    # display prediction from highest to lowest maximum likelihood\n",
    "    prediction = sorted(dict(model[prev_words[0], prev_words[1]]), key=lambda x: dict(model[prev_words[0], prev_words[1]])[x], reverse=True)\n",
    "    print(\"Trigram model predictions: \", prediction)\n",
    "\n",
    "    word = []\n",
    "    weight = []\n",
    "    for key, prob in dict(model[prev_words[0], prev_words[1]]).items():\n",
    "        word.append(key)\n",
    "        weight.append(prob)\n",
    "    # pick from a weighted random probability of predictions\n",
    "    next_word = random.choices(word, weights=weight, k=1)\n",
    "    # add predicted word to user input\n",
    "    user_input.append(next_word[0])\n",
    "    print(' '.join(user_input))\n",
    "\n",
    "    ask = input(\"Do you want to generate another word? (type 'y' for yes or 'n' for no): \")\n",
    "    if ask.lower() == 'y':\n",
    "        predict(model, str(user_input))\n",
    "    elif ask.lower() == 'n':\n",
    "        print(\"done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e0d48-bc6c-47cf-b6bc-57fa81b8847d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering...\n",
      "Cleaning...\n",
      "Making model...\n",
      "Enter a phrase: \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
